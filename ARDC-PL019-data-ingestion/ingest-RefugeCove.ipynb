{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2ff2fb6-df55-436d-beba-bd7e1e722b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import io\n",
    "import urllib\n",
    "import s3fs\n",
    "import json\n",
    "from pathlib import Path\n",
    "import attr\n",
    "import numpy\n",
    "import tiledb\n",
    "import tiledb.cloud\n",
    "from tiledb.cloud.compute import DelayedArrayUDF, Delayed\n",
    "import pandas\n",
    "import geopandas\n",
    "import fiona\n",
    "from fiona.session import AWSSession\n",
    "import pystac\n",
    "from scipy.stats import skew, kurtosis\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99313258-b90d-4d66-9cc7-9bd6b766f94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pystac\n",
    "from pystac.extensions.projection import ProjectionExtension\n",
    "from pystac.extensions.pointcloud import (\n",
    "    PointcloudExtension,\n",
    "    SchemaType,\n",
    "    PhenomenologyType,\n",
    "    Schema,\n",
    "    Statistic,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a2e6b0e-f2e8-4627-8d50-6bd5b9fdf929",
   "metadata": {},
   "outputs": [],
   "source": [
    "from reap_gsf import reap, data_model\n",
    "from bathy_datasets import rhealpix, storage, geometry, asb_spreadsheet, stac_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4adea867-c8e1-4722-a44b-c14030819102",
   "metadata": {},
   "outputs": [],
   "source": [
    "session = boto3.Session()\n",
    "creds = session.get_credentials()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf5002e4-b91e-4e2a-a594-fca75013f2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = s3fs.S3FileSystem(key=creds.access_key, secret=creds.secret_key, use_listings_cache=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7346bb6b-dbe5-4819-85f9-478e5d0f3cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "uid = uuid.uuid4()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "05a98da2-c2d7-46cf-b58c-f3dab30943a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_uri = \"s3://ausseabed-pl019-provided-data/DeakinUniversity/RefugeCove/\"\n",
    "outdir_uri = \"s3://ausseabed-pl019-ingested-data/L2/RefugeCove/\"\n",
    "asb_metadata_uri = \"s3://ausseabed-pl019-provided-data/DeakinUniversity/RefugeCove/metadata/spreadsheet-metadata.json\"\n",
    "survey_info_uri = \"s3://ausseabed-pl019-provided-data/DeakinUniversity/RefugeCove/schema-info.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "04f74150-515e-45bf-bce2-946358e96c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_prefix = \"ga_ausseabed\"\n",
    "array_name = f\"{base_prefix}_{uid}_bathymetry\"\n",
    "array_uri = f\"{outdir_uri}{array_name}.tiledb\"\n",
    "tiledb_array_uri = f\"tiledb://sixy6e/{array_name}\"\n",
    "soundings_cell_density_uri = f\"{outdir_uri}{base_prefix}_{uid}_soundings-cell-density-resolution-12.geojson\"\n",
    "coverage_uri = f\"{outdir_uri}{base_prefix}_{uid}_coverage.geojson\"\n",
    "stac_md_uri = f\"{outdir_uri}{base_prefix}_{uid}_stac-metadata.geojson\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7be60ec4-ffad-4cd0-ab8d-df4bca675f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "soundings_cell_density_uri_15 = f\"{outdir_uri}{base_prefix}_{uid}_soundings-cell-density-resolution-15.geojson\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b31e99c2-1741-46e5-abe6-2787a9d034f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sonar_metadata(json_uri):\n",
    "    \"\"\"\n",
    "    Temporary func for pulling metadata from a sample GSF file.\n",
    "    \"\"\"\n",
    "    with fs.open(json_uri) as src:\n",
    "        md = json.loads(src.read())\n",
    "    stream_task = Delayed(\"sixy6e/retrieve_stream\", name=\"retrieve\")(md[\"gsf_uri\"], creds.access_key, creds.secret_key)\n",
    "    dataframe_task = Delayed(\"sixy6e/decode_gsf\", name=\"decode\", image_name=\"3.7-geo\")(stream_task, slice(10))\n",
    "    df, finfo = dataframe_task.compute()\n",
    "    sonar_metadata = finfo[3].record(0).read(stream_task.result()[0])\n",
    "    history = attr.asdict(finfo[6].record(0).read(stream_task.result()[0]))\n",
    "    for key, value in history.items():\n",
    "        sonar_metadata[key] = value\n",
    "    return sonar_metadata\n",
    "\n",
    "\n",
    "def reduce_region_codes(results):\n",
    "    \"\"\"\n",
    "    The reduce part of the map-reduce construct for handling the region_code counts.\n",
    "    Combine all the region_code counts then summarise the results.\n",
    "    \"\"\"\n",
    "    region_codes = [i[0] for i in results]\n",
    "    timestamps = [i[1] for i in results]\n",
    "    df = pandas.concat(region_codes)\n",
    "    cell_count = df.groupby([\"region_code\"])[\"count\"].agg(\"sum\").to_frame(\"count\").reset_index()\n",
    "    \n",
    "    timestamps_df = pandas.DataFrame(\n",
    "        {\n",
    "            \"start_datetime\": [i[0] for i in timestamps],\n",
    "            \"end_datetime\": [i[1] for i in timestamps],\n",
    "        }\n",
    "    )\n",
    "\n",
    "    start_end_timestamp = [\n",
    "        timestamps_df.start_datetime.min().to_pydatetime(),\n",
    "        timestamps_df.end_datetime.max().to_pydatetime(),\n",
    "    ]\n",
    "\n",
    "    return cell_count, start_end_timestamp\n",
    "\n",
    "\n",
    "def gather_stats(results):\n",
    "    \"\"\"\n",
    "    Gather the results from all the stats tasks and\n",
    "    combine into a single dict.\n",
    "    \"\"\"\n",
    "    data = {}\n",
    "    for item in results:\n",
    "        for key in item:\n",
    "            data[key] = item[key]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "daa0bd82-2565-4964-af3c-420197c6dea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_stream(uri, access_key, skey):\n",
    "    \"\"\"\n",
    "    Not testing the creation of the stream object at this point.\n",
    "    But for testing, we also need to keep the download to occur only\n",
    "    once.\n",
    "    \"\"\"\n",
    "    session = boto3.Session(aws_access_key_id=access_key, aws_secret_access_key=skey)\n",
    "    dev_resource = session.resource(\"s3\")\n",
    "    uri = urllib.parse.urlparse(uri)\n",
    "    obj = dev_resource.Object(bucket_name=uri.netloc, key=uri.path[1:])\n",
    "    stream = io.BytesIO(obj.get()[\"Body\"].read())\n",
    "    return stream, obj.content_length\n",
    "\n",
    "\n",
    "def append_ping_dataframe(dataframe, array_uri, access_key, skey):\n",
    "    \"\"\"Append the ping dataframe read from a GSF file.\"\"\"\n",
    "    config = tiledb.Config(\n",
    "        {\"vfs.s3.aws_access_key_id\": access_key, \"vfs.s3.aws_secret_access_key\": skey}\n",
    "    )\n",
    "    ctx = tiledb.Ctx(config=config)\n",
    "    kwargs = {\n",
    "        \"mode\": \"append\",\n",
    "        \"sparse\": True,\n",
    "        \"ctx\": ctx,\n",
    "    }\n",
    "\n",
    "    tiledb.dataframe_.from_pandas(array_uri, dataframe, **kwargs)\n",
    "\n",
    "\n",
    "def ingest_gsf_slice(\n",
    "    file_record, stream, access_key, skey, array_uri, idx=slice(None)\n",
    "):\n",
    "    \"\"\"\n",
    "    General steps:\n",
    "    Extract the ping data.\n",
    "    Calculate the rHEALPIX code.\n",
    "    Summarise the rHEALPIX codes (frequency count).\n",
    "    Get timestamps of first and last pings.\n",
    "    Write the ping data to a TileDB array.\n",
    "    res = [df.groupby([\"key\"])[\"key\"].agg(\"count\").to_frame(\"count\").reset_index() for i in range(3)]\n",
    "    df2 = pandas.concat(res)\n",
    "    df2.groupby([\"key\"])[\"count\"].agg(\"sum\")\n",
    "    \"\"\"\n",
    "    swath_pings = data_model.SwathBathymetryPing.from_records(file_record, stream, idx)\n",
    "    swath_pings.ping_dataframe[\"region_code\"] = rhealpix.rhealpix_code(\n",
    "        swath_pings.ping_dataframe.X, swath_pings.ping_dataframe.Y, 15\n",
    "    )\n",
    "\n",
    "    # frequency of dggs cells\n",
    "    cell_count = (\n",
    "        swath_pings.ping_dataframe.groupby([\"region_code\"])[\"region_code\"]\n",
    "        .agg(\"count\")\n",
    "        .to_frame(\"count\")\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    start_end_time = [\n",
    "        swath_pings.ping_dataframe.timestamp.min().to_pydatetime(),\n",
    "        swath_pings.ping_dataframe.timestamp.max().to_pydatetime(),\n",
    "    ]\n",
    "\n",
    "    # write to tiledb array\n",
    "    append_ping_dataframe(swath_pings.ping_dataframe, array_uri, access_key, skey)\n",
    "\n",
    "    return cell_count, start_end_time\n",
    "\n",
    "\n",
    "def ingest_gsf_slices(gsf_uri, access_key, skey, array_uri, slices):\n",
    "    \"\"\"\n",
    "    Ingest a list of ping slices from a given GSF file.\n",
    "    \"\"\"\n",
    "    stream, stream_length = retrieve_stream(gsf_uri, access_key, skey)\n",
    "    finfo = reap.file_info(stream, stream_length)\n",
    "    ping_file_record = finfo[1]\n",
    "\n",
    "    cell_counts = []\n",
    "    start_end_timestamps = []\n",
    "\n",
    "    for idx in slices:\n",
    "        count, start_end_time = ingest_gsf_slice(\n",
    "            ping_file_record, stream, access_key, skey, array_uri, idx\n",
    "        )\n",
    "        cell_counts.append(count)\n",
    "        start_end_timestamps.append(start_end_time)\n",
    "\n",
    "    # aggreate the ping slices and calculate the cell counts\n",
    "    concatenated = pandas.concat(cell_counts)\n",
    "    cell_count = (\n",
    "        concatenated.groupby([\"region_code\"])[\"count\"]\n",
    "        .agg(\"sum\")\n",
    "        .to_frame(\"count\")\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    # aggregate the min and max timestamps, then find the min max timestamps\n",
    "    timestamps_df = pandas.DataFrame(\n",
    "        {\n",
    "            \"start_datetime\": [i[0] for i in start_end_timestamps],\n",
    "            \"end_datetime\": [i[1] for i in start_end_timestamps],\n",
    "        }\n",
    "    )\n",
    "\n",
    "    start_end_timestamp = [\n",
    "        timestamps_df.start_datetime.min().to_pydatetime(),\n",
    "        timestamps_df.end_datetime.max().to_pydatetime(),\n",
    "    ]\n",
    "\n",
    "    return cell_count, start_end_timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "96f9340b-b1a2-4a5d-98a8-07a33079cab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scatter(iterable, n):\n",
    "    \"\"\"\n",
    "    Evenly scatters an interable by `n` blocks.\n",
    "    Sourced from:\n",
    "    http://stackoverflow.com/questions/2130016/splitting-a-list-of-arbitrary-size-into-only-roughly-n-equal-parts\n",
    "\n",
    "    :param iterable:\n",
    "        An iterable or preferably a 1D list or array.\n",
    "\n",
    "    :param n:\n",
    "        An integer indicating how many blocks to create.\n",
    "\n",
    "    :return:\n",
    "        A `list` consisting of `n` blocks of roughly equal size, each\n",
    "        containing elements from `iterable`.\n",
    "    \"\"\"\n",
    "\n",
    "    q, r = len(iterable) // n, len(iterable) % n\n",
    "    res = (iterable[i * q + min(i, r) : (i + 1) * q + min(i + 1, r)] for i in range(n))\n",
    "    return list(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "12b4f395-2463-4520-b5d2-d1e1bda96a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ingest_gsfs(files, size_limit_mb, processing_node_limit, ping_slice_step, slices_per_node):\n",
    "    \"\"\"\n",
    "    Prototype ingester.\n",
    "    \"\"\"\n",
    "\n",
    "    node_counter = 0\n",
    "    skipped_files = []\n",
    "    large_files = []\n",
    "    tasks = []\n",
    "    tasks_dict = {n: [] for n in range(processing_node_limit)}\n",
    "\n",
    "    for pathname in files:\n",
    "        metadata_pathname = pathname.replace(\".gsf\", \".json\")\n",
    "        base_name = Path(pathname).stem\n",
    "        with fs.open(metadata_pathname) as src:\n",
    "            gsf_metadata = json.loads(src.read())\n",
    "\n",
    "        if (gsf_metadata[\"size\"] / 1024 / 1024) > size_limit_mb:\n",
    "            large_files.append(pathname)\n",
    "            continue\n",
    "\n",
    "        ping_count = gsf_metadata[\"file_record_types\"][\"GSF_SWATH_BATHYMETRY_PING\"][\"record_count\"]\n",
    "        if ping_count == 0:\n",
    "            skipped_files.append(pathname)\n",
    "            continue\n",
    "\n",
    "        slices = [slice(start, start+ping_slice_step) for start in numpy.arange(0, ping_count, ping_slice_step)]\n",
    "        slice_chunks = [slices[i:i+slices_per_node] for i in range(0, len(slices), slices_per_node)]\n",
    "\n",
    "        for slice_chunk in slice_chunks:\n",
    "            start_idx = slice_chunk[0].start\n",
    "            end_idx = slice_chunk[0].stop\n",
    "            task_name = f\"{base_name}-{start_idx}-{end_idx}-{node_counter}\"\n",
    "            task = Delayed(\"sixy6e/ingest_gsf_slices\", name=task_name, image_name=\"3.7-geo\")(gsf_metadata[\"gsf_uri\"], creds.access_key, creds.secret_key, array_uri, slice_chunk)\n",
    "            task.set_timeout(1800)\n",
    "\n",
    "            if len(tasks_dict[node_counter]):\n",
    "                task.depends_on(tasks_dict[node_counter][-1])\n",
    "\n",
    "            tasks.append(task)\n",
    "            tasks_dict[node_counter].append(task)\n",
    "            node_counter += 1\n",
    "\n",
    "            if node_counter == processing_node_limit:\n",
    "                node_counter = 0\n",
    "\n",
    "    reduce_task = Delayed(reduce_region_codes, \"reduce-region_codes-timestamps\", local=True)(tasks)\n",
    "    \n",
    "    return reduce_task, skipped_files, large_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c9fccb78-336d-4368-99d3-4284fc57fd87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ingest_gsfs_local(files, size_limit_mb, processing_node_limit, ping_slice_step, slices_per_node):\n",
    "    \"\"\"\n",
    "    Prototype ingester.\n",
    "    \"\"\"\n",
    "\n",
    "    node_counter = 0\n",
    "    skipped_files = []\n",
    "    large_files = []\n",
    "    tasks = []\n",
    "    tasks_dict = {n: [] for n in range(processing_node_limit)}\n",
    "\n",
    "    for pathname in files:\n",
    "        metadata_pathname = pathname.replace(\".gsf\", \".json\")\n",
    "        base_name = Path(pathname).stem\n",
    "        with fs.open(metadata_pathname) as src:\n",
    "            gsf_metadata = json.loads(src.read())\n",
    "\n",
    "        #if (gsf_metadata[\"size\"] / 1024 / 1024) > size_limit_mb:\n",
    "        #    large_files.append(pathname)\n",
    "        #    continue\n",
    "\n",
    "        ping_count = gsf_metadata[\"file_record_types\"][\"GSF_SWATH_BATHYMETRY_PING\"][\"record_count\"]\n",
    "        if ping_count == 0:\n",
    "            skipped_files.append(pathname)\n",
    "            continue\n",
    "\n",
    "        slices = [slice(start, start+ping_slice_step) for start in numpy.arange(0, ping_count, ping_slice_step)]\n",
    "        slice_chunks = [slices[i:i+slices_per_node] for i in range(0, len(slices), slices_per_node)]\n",
    "\n",
    "        for slice_chunk in slice_chunks:\n",
    "            start_idx = slice_chunk[0].start\n",
    "            end_idx = slice_chunk[0].stop\n",
    "            task_name = f\"{base_name}-{start_idx}-{end_idx}-{node_counter}\"\n",
    "            task = Delayed(ingest_gsf_slices, name=task_name, local=True)(gsf_metadata[\"gsf_uri\"], creds.access_key, creds.secret_key, array_uri, slice_chunk)\n",
    "            task.set_timeout(1800)\n",
    "\n",
    "            if len(tasks_dict[node_counter]):\n",
    "                task.depends_on(tasks_dict[node_counter][-1])\n",
    "\n",
    "            tasks.append(task)\n",
    "            tasks_dict[node_counter].append(task)\n",
    "            node_counter += 1\n",
    "\n",
    "            if node_counter == processing_node_limit:\n",
    "                node_counter = 0\n",
    "\n",
    "    reduce_task = Delayed(reduce_region_codes, \"reduce-region_codes-timestamps\", local=True)(tasks)\n",
    "    \n",
    "    return reduce_task, skipped_files, large_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "33750be7-1f1a-4555-af94-b52700212141",
   "metadata": {},
   "outputs": [],
   "source": [
    "with fs.open(survey_info_uri) as src:\n",
    "    survey_info = json.loads(src.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "87baf7dc-9a6b-401d-b2d7-8e1d9fad42ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#required_attributes = survey_info[\"schemas\"][0]\n",
    "# this is temporary. better to have it defined internally. or programmatically derived as a union of all schemas from all pings\n",
    "required_attributes = [\n",
    "    \"Z\",\n",
    "    \"across_track\",\n",
    "    \"along_track\",\n",
    "    \"beam_angle\",\n",
    "    \"beam_angle_forward\",\n",
    "    \"beam_flags\",\n",
    "    \"beam_number\",\n",
    "    \"centre_beam\",\n",
    "    \"course\",\n",
    "    \"depth_corrector\",\n",
    "    \"gps_tide_corrector\",\n",
    "    \"heading\",\n",
    "    \"heave\",\n",
    "    \"height\",\n",
    "    \"horizontal_error\",\n",
    "    \"ping_flags\",\n",
    "    \"pitch\",\n",
    "    \"roll\",\n",
    "    \"sector_number\",\n",
    "    \"separation\",\n",
    "    \"speed\",\n",
    "    \"tide_corrector\",\n",
    "    \"timestamp\",\n",
    "    \"travel_time\",\n",
    "    \"vertical_error\",\n",
    "    \"region_code\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d70c1529-bbce-4a60-9981-809af8656a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tiledb.Config(\n",
    "        {\"vfs.s3.aws_access_key_id\": creds.access_key, \"vfs.s3.aws_secret_access_key\": creds.secret_key}\n",
    "    )\n",
    "config_dict = config.dict()\n",
    "ctx = tiledb.Ctx(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f479ddbb-cb10-4be4-8041-e90ed49c0b42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8ca86ec9-0ba1-4051-8dfb-e13d223cb309",
   "metadata": {},
   "outputs": [],
   "source": [
    "storage.create_mbes_array(array_uri, required_attributes, ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c332aa-6b68-4ca1-bd0c-b504cd08c7d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0cb10957-0f9a-4eda-a7d1-3a4b1999590b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = fs.glob(survey_uri + \"**.gsf\")\n",
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aef01212-d8a9-4898-9b0e-a9f18a269848",
   "metadata": {},
   "outputs": [],
   "source": [
    "sonar_metadata = get_sonar_metadata(files[1].replace(\".gsf\", \".json\"))  # files[1] exceeds the memory limit of the UDF instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf952de-bbbe-4f87-b69b-676169c04cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a lot of the GSF's in this survey are very slow read. Suggesting that pings are spaced very far apart in the file\n",
    "# so lots of seeking through the file to get to the specific byte to start reading from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "07345d87-edfa-48f9-9bbe-cc0b7554e6f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_partitions = 3\n",
    "files_blocks = scatter(files, n_partitions)\n",
    "len(files_blocks[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b551833f-f781-4c50-9c86-1b919aeb3f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "size_limit_mb = 500\n",
    "processing_node_limit = 5\n",
    "ping_slice_step = 2000\n",
    "slices_per_node = 3\n",
    "local_tasks_limit = 1\n",
    "local_ping_slice_step = 2000\n",
    "local_slices_per_task = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "aa36e932-5669-40fa-982e-56fa1d48f3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "skipped_files = []\n",
    "large_files = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1f0600fc-7f2c-4d07-a46e-17d1dcb6cf1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_task, skipped_files1, large_files1 = ingest_gsfs(files_blocks[0], size_limit_mb, processing_node_limit, ping_slice_step, slices_per_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "217d5064-db1e-4d21-9ae7-1b85d3ca3dfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "679b42695af74cf28906301811ceaa9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Visualize(value='{\"nodes\": [\"d1e34e38-6e93-42ab-9baf-0678813eb21f\", \"6e309de9-b5ba-4a55-9d0a-cb666e95821c\", \"3…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "reduce_task.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3ba99e39-41a0-462f-a22a-645c81f96ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_count_df1, start_end_timestamps1 = reduce_task.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5ed64a1e-39d9-47c0-8a65-4a27822fdd0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_task, skipped_files2, large_files2 = ingest_gsfs(files_blocks[1], size_limit_mb, processing_node_limit, ping_slice_step, slices_per_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "57840e94-dfbe-4aa8-9ea8-07f4401f729e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2b0e20ba7674863812471b9aa18bbcf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Visualize(value='{\"nodes\": [\"91e1d2a7-d511-49e6-9b59-2fc57294564a\", \"866065bc-179f-4d99-a8c1-f5bf5ee8437b\", \"f…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "reduce_task.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "58dc7620-9439-4297-920f-be37d110dad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_count_df2, start_end_timestamps2 = reduce_task.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a991e965-4e65-44d6-9100-bd18b86f0730",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_task, skipped_files3, large_files3 = ingest_gsfs(files_blocks[2], size_limit_mb, processing_node_limit, ping_slice_step, slices_per_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3ab29cea-fdf8-40f1-b8d7-35dceb8dd2f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e3fd603eff0434bba928827e30ffa96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Visualize(value='{\"nodes\": [\"ce82633a-6083-4812-9b53-edb36d929b3e\", \"cfa95439-d4e8-4c6a-a5c9-9b10e2759e1b\", \"4…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "reduce_task.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "bbf01ee6-2642-4590-8a92-1fade4e5ad9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_count_df3, start_end_timestamps3 = reduce_task.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8e8b3297-f29c-4109-bfe4-531515b79a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "large_files.extend(large_files1)\n",
    "large_files.extend(large_files2)\n",
    "large_files.extend(large_files3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "231c9081-bce1-4063-bb56-74bd03056280",
   "metadata": {},
   "outputs": [],
   "source": [
    "skipped_files.extend(skipped_files1)\n",
    "skipped_files.extend(skipped_files2)\n",
    "skipped_files.extend(skipped_files3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "61c9f0d8-71fb-480b-bcb4-32667ad53e14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(large_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "39957e9d-70cd-4675-ad8c-122fe523673c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(skipped_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "83e6580c-b6b6-47a5-a493-c75042f5f101",
   "metadata": {},
   "outputs": [],
   "source": [
    "# local compute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "5529d654-96c6-4f07-a64b-bda080313e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_task, skipped_files_local, large_files_local = ingest_gsfs_local(large_files, size_limit_mb, local_tasks_limit, local_ping_slice_step, local_slices_per_task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e163d4b9-42ad-411c-bd7b-455ba3ad2ed7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57a5c912f7f94824b222124c34552b29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Visualize(value='{\"nodes\": [\"e45ac830-e884-4f66-b847-089b244ffae6\", \"4a6c2b6c-65a1-4790-8492-a6b37afcc9c7\", \"7…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "reduce_task.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "75fb0f12-9c13-423a-a110-f1d2ceb29513",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_count_df_local, start_end_timestamps_local = reduce_task.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ffec935-f406-4bf2-a520-d0432891f8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect and reduce dataframes and ping start end times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "28865148-b3a6-4e74-bfbe-29cdde288eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_non_local_results = [\n",
    "    [cell_count_df1, start_end_timestamps1],\n",
    "    [cell_count_df2, start_end_timestamps2],\n",
    "    [cell_count_df3, start_end_timestamps3],\n",
    "    [cell_count_df_local, start_end_timestamps_local],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "1f0948d1-924a-4064-a5ee-2197fe641bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_cell_count_df, final_start_end_timestamps = reduce_region_codes(local_non_local_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a33a9ac8-cf4d-4c9e-8203-18b146a6b7ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>region_code</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>R787257760375582</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>R787257760375584</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>R787257760375585</td>\n",
       "      <td>599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>R787257760375586</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>R787257760375587</td>\n",
       "      <td>904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1019800</th>\n",
       "      <td>R787257767001303</td>\n",
       "      <td>148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1019801</th>\n",
       "      <td>R787257767001305</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1019802</th>\n",
       "      <td>R787257767001308</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1019803</th>\n",
       "      <td>R787257767001310</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1019804</th>\n",
       "      <td>R787257767001321</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1019805 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              region_code  count\n",
       "0        R787257760375582      2\n",
       "1        R787257760375584     53\n",
       "2        R787257760375585    599\n",
       "3        R787257760375586    400\n",
       "4        R787257760375587    904\n",
       "...                   ...    ...\n",
       "1019800  R787257767001303    148\n",
       "1019801  R787257767001305      1\n",
       "1019802  R787257767001308     37\n",
       "1019803  R787257767001310    113\n",
       "1019804  R787257767001321      5\n",
       "\n",
       "[1019805 rows x 2 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_cell_count_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "fba5bf1b-14f1-410a-8257-318e5f64d4e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[datetime.datetime(2013, 6, 7, 5, 44, 37, 467000),\n",
       " datetime.datetime(2013, 6, 11, 3, 7, 41, 51000)]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_start_end_timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "07be7419-a7e5-41a4-8f71-9d0d714553b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_cell_count_df[\"geometry\"] = rhealpix.rhealpix_geo_boundary(final_cell_count_df.region_code.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "161d3b37-fd4c-4b28-8808-8ef370baa9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_15 = geopandas.GeoDataFrame(final_cell_count_df, crs=\"epsg:4326\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "2e982126-42a0-4743-b56b-0cce0ea7ed7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with fiona.Env(session=AWSSession(aws_access_key_id=creds.access_key, aws_secret_access_key=creds.secret_key)):\n",
    "    gdf_15.to_file(soundings_cell_density_uri_15, driver=\"GeoJSONSeq\", coordinate_precision=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "0479b0ad-088a-4a11-8fef-ef35cf00182b",
   "metadata": {},
   "outputs": [],
   "source": [
    "resolution12_df = pandas.DataFrame(\n",
    "    {\n",
    "        \"region_code\": final_cell_count_df.region_code.str[0:13],\n",
    "        \"count\": final_cell_count_df[\"count\"],\n",
    "    }\n",
    ").groupby(\n",
    "    [\"region_code\"]\n",
    ")[\"count\"].agg(\"sum\").to_frame(\"count\").reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a748bf2c-9495-4e5a-aaeb-22a4459bac24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>region_code</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>R787257760375</td>\n",
       "      <td>58486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>R787257760377</td>\n",
       "      <td>92645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>R787257760378</td>\n",
       "      <td>300922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>R787257760380</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>R787257760381</td>\n",
       "      <td>120824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1512</th>\n",
       "      <td>R787257766220</td>\n",
       "      <td>431895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1513</th>\n",
       "      <td>R787257766221</td>\n",
       "      <td>505232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1514</th>\n",
       "      <td>R787257766222</td>\n",
       "      <td>554068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1515</th>\n",
       "      <td>R787257767000</td>\n",
       "      <td>767308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1516</th>\n",
       "      <td>R787257767001</td>\n",
       "      <td>407982</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1517 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        region_code   count\n",
       "0     R787257760375   58486\n",
       "1     R787257760377   92645\n",
       "2     R787257760378  300922\n",
       "3     R787257760380       9\n",
       "4     R787257760381  120824\n",
       "...             ...     ...\n",
       "1512  R787257766220  431895\n",
       "1513  R787257766221  505232\n",
       "1514  R787257766222  554068\n",
       "1515  R787257767000  767308\n",
       "1516  R787257767001  407982\n",
       "\n",
       "[1517 rows x 2 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resolution12_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b240088f-699e-46ec-98c5-db9f1259ea78",
   "metadata": {},
   "outputs": [],
   "source": [
    "resolution12_df[\"geometry\"] = rhealpix.rhealpix_geo_boundary(resolution12_df.region_code.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "f99ce23a-cabc-4865-afe2-ca9fcb578247",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = geopandas.GeoDataFrame(resolution12_df, crs=\"epsg:4326\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "9292507b-2752-456d-b8a6-cd8332334593",
   "metadata": {},
   "outputs": [],
   "source": [
    "with fiona.Env(session=AWSSession(aws_access_key_id=creds.access_key, aws_secret_access_key=creds.secret_key)):\n",
    "    gdf.to_file(soundings_cell_density_uri, driver=\"GeoJSONSeq\", coordinate_precision=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "530779e8-09b7-4030-a434-b1d71233c8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "dissolved = geopandas.GeoDataFrame(geometry.dissolve(gdf), crs=\"epsg:4326\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "d145965f-89d0-4efd-84a2-65abba740cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with fiona.Env(session=AWSSession(aws_access_key_id=creds.access_key, aws_secret_access_key=creds.secret_key)):\n",
    "    dissolved.to_file(coverage_uri, driver=\"GeoJSONSeq\", coordinate_precision=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "aecce02c-ed81-4e8d-b8a2-979f8b53b91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dggs = rhealpix.RhealpixDGGS.from_ellipsoid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "66742e4c-dba1-49da-a3ee-91341468a831",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18.8309796906348"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dggs.cell_width(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "cc29448b-4009-48f5-945a-3c7611446591",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53.793699269750505"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "area_ha = gdf.shape[0] * dggs.cell_width(12) **2 / 10000\n",
    "sonar_metadata[\"area_ha\"] = area_ha\n",
    "area_ha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "fc28417d-7989-4bc5-927b-0fb84c6dfc4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with fs.open(asb_metadata_uri) as src:\n",
    "    asb_metadata = json.loads(src.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "f7c2f6ab-bb4f-48a4-865c-8e9ae490f4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tiledb.cloud.register_array(\n",
    "    uri=array_uri,\n",
    "    namespace=\"sixy6e\", # Optional, you may register it under your username, or one of your organizations\n",
    "    array_name=array_name,\n",
    "    description=asb_metadata[\"survey_general\"][\"abstract\"],  # Optional \n",
    "    access_credentials_name=\"AusSeabedGMRT-PL019\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "d7a1073d-5b97-49b5-bd39-6fc956bb3b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tiledb.open(array_uri, ctx=ctx) as ds:\n",
    "    schema = ds.schema\n",
    "    domain = ds.domain\n",
    "    non_empty_domain = ds.nonempty_domain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "5ea94e5c-995a-44aa-8131-5d94423c5d40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2340210"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdf[\"count\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "93d8907f-36d2-4708-abf0-262b60041e35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdf[\"count\"].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "9e55298d-ce90-4de4-9810-ecf6167a2532",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(slice(146.46094207073315, 146.47336965970928, None),\n",
       " slice(-39.04230695031783, -39.034863253466206, None))"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_idx = (slice(*non_empty_domain[0]), slice(*non_empty_domain[1]))\n",
    "full_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "b75ca351-400f-4093-a6ee-8503ee7aaa29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test first to see if stats can be generated with full domain, or if we need to iterate over region codes\n",
    "# use the X from the schema. This should use the most memory. if it fails then use the scatter approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b9f8be-8c65-4520-842c-c72aa819939d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# task = Delayed(\"sixy6e/basic_statistics_incremental\", name=\"test-X-stat-full-idx\")(array_uri, config_dict, \"X\", schema=\"X\", idxs=[full_idx], summarise=True)\n",
    "# result = task.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c809df4c-4d4b-48c9-81a3-cfab352d7fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduce the region code resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "0195265c-782a-482d-ade3-bba45350e609",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf2 = geopandas.GeoDataFrame({\"region_code\": gdf.region_code.str[0:11], \"count\": gdf[\"count\"]}).groupby([\"region_code\"])[\"count\"].agg(\"sum\").to_frame(\"count\").reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "21aac863-b770-4b24-aa12-72efeec422a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>region_code</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>R7872577603</td>\n",
       "      <td>2389405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>R7872577604</td>\n",
       "      <td>10524841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>R7872577605</td>\n",
       "      <td>5205351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>R7872577606</td>\n",
       "      <td>13574041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>R7872577607</td>\n",
       "      <td>5851555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>R7872577608</td>\n",
       "      <td>4231878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>R7872577616</td>\n",
       "      <td>1987928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>R7872577617</td>\n",
       "      <td>1512787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>R7872577618</td>\n",
       "      <td>2795304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>R7872577623</td>\n",
       "      <td>113341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>R7872577624</td>\n",
       "      <td>354483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>R7872577625</td>\n",
       "      <td>6177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>R7872577626</td>\n",
       "      <td>2727962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>R7872577627</td>\n",
       "      <td>629116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>R7872577628</td>\n",
       "      <td>4035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>R7872577630</td>\n",
       "      <td>5379280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>R7872577631</td>\n",
       "      <td>4986196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>R7872577632</td>\n",
       "      <td>3445943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>R7872577634</td>\n",
       "      <td>2417933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>R7872577635</td>\n",
       "      <td>4602065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>R7872577637</td>\n",
       "      <td>187296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>R7872577638</td>\n",
       "      <td>29060844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>R7872577640</td>\n",
       "      <td>2367146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>R7872577641</td>\n",
       "      <td>1970799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>R7872577642</td>\n",
       "      <td>1439369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>R7872577643</td>\n",
       "      <td>3489728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>R7872577644</td>\n",
       "      <td>2884977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>R7872577645</td>\n",
       "      <td>1032851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>R7872577646</td>\n",
       "      <td>15355967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>R7872577647</td>\n",
       "      <td>74838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>R7872577650</td>\n",
       "      <td>693803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>R7872577651</td>\n",
       "      <td>11278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>R7872577653</td>\n",
       "      <td>15872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>R7872577662</td>\n",
       "      <td>1790721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>R7872577670</td>\n",
       "      <td>1175290</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    region_code     count\n",
       "0   R7872577603   2389405\n",
       "1   R7872577604  10524841\n",
       "2   R7872577605   5205351\n",
       "3   R7872577606  13574041\n",
       "4   R7872577607   5851555\n",
       "5   R7872577608   4231878\n",
       "6   R7872577616   1987928\n",
       "7   R7872577617   1512787\n",
       "8   R7872577618   2795304\n",
       "9   R7872577623    113341\n",
       "10  R7872577624    354483\n",
       "11  R7872577625      6177\n",
       "12  R7872577626   2727962\n",
       "13  R7872577627    629116\n",
       "14  R7872577628      4035\n",
       "15  R7872577630   5379280\n",
       "16  R7872577631   4986196\n",
       "17  R7872577632   3445943\n",
       "18  R7872577634   2417933\n",
       "19  R7872577635   4602065\n",
       "20  R7872577637    187296\n",
       "21  R7872577638  29060844\n",
       "22  R7872577640   2367146\n",
       "23  R7872577641   1970799\n",
       "24  R7872577642   1439369\n",
       "25  R7872577643   3489728\n",
       "26  R7872577644   2884977\n",
       "27  R7872577645   1032851\n",
       "28  R7872577646  15355967\n",
       "29  R7872577647     74838\n",
       "30  R7872577650    693803\n",
       "31  R7872577651     11278\n",
       "32  R7872577653     15872\n",
       "33  R7872577662   1790721\n",
       "34  R7872577670   1175290"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdf2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "a09bc84c-d2e4-44a1-8f8e-53051ce575d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "slices = []\n",
    "for geom in rhealpix.rhealpix_geo_boundary(gdf2.region_code.values, round_coords=False):\n",
    "    bounds = geom.bounds\n",
    "    slices.append((\n",
    "        slice(bounds[0], bounds[-2]),\n",
    "        slice(bounds[1], bounds[-1])\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "da032dc5-a52b-4444-b781-b9af286a23f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_partitions = 2\n",
    "n_sub_partitions = 2\n",
    "blocks = scatter(slices, n_partitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "ce8c309d-8b09-4f33-9ecc-bde959c70387",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 18)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(blocks), len(blocks[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "ab536a79-e0c2-443a-a0e1-d19bc91964a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(scatter(blocks[0], n_sub_partitions)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "a1c3844b-41fb-4319-b3fb-1f22c12c0df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_attrs = [at for at in required_attributes if at not in [\"timestamp\", \"region_code\"]]\n",
    "stats_attrs.insert(0, \"Y\")\n",
    "stats_attrs.insert(0, \"X\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "a2fcc74e-ba78-4f9b-b089-ea05d4ac02b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_results = []\n",
    "tasks_dict = {stat: [] for stat in stats_attrs}\n",
    "reduce_tasks = []\n",
    "\n",
    "for i, block in enumerate(blocks):\n",
    "    sub_tasks = []\n",
    "    sub_blocks = scatter(block, n_sub_partitions)\n",
    "\n",
    "    for si, sub_block in enumerate(sub_blocks):\n",
    "        for attribute in stats_attrs:\n",
    "            \n",
    "            if attribute in [\"X\", \"Y\"]:\n",
    "                schema = attribute\n",
    "            else:\n",
    "                schema = None\n",
    "\n",
    "            task_name = f\"block-{i}-sub_block-{si}-{attribute}\"\n",
    "            task = Delayed(\"sixy6e/basic_statistics_incremental\", name=task_name)(array_uri, config_dict, attribute, schema=schema, idxs=sub_block, summarise=False)\n",
    "\n",
    "            if len(tasks_dict[attribute]) > 1:\n",
    "                task.depends_on(tasks_dict[attribute][-1])\n",
    "\n",
    "            tasks_dict[attribute].append(task)\n",
    "\n",
    "for attribute in stats_attrs:\n",
    "    task_name = f\"reduce-attibute-{attribute}\"\n",
    "    reducer_task = Delayed(\"sixy6e/basic_statistics_reduce\", name=task_name)(tasks_dict[attribute], attribute)\n",
    "    reduce_tasks.append(reducer_task)\n",
    "\n",
    "collect_stats_task = Delayed(gather_stats, local=True, name=\"gather-stats\")(reduce_tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "e4773fe0-ec7d-4c21-9932-8f37c03830a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_results = collect_stats_task.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "15f4d81f-f4c6-4e06-ad0b-7ba03f79a182",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'survey_general': {'survey_title': 'Refuge Cove Bathymetry Survey',\n",
       "  'survey_id': 'Refuge Cove Bathymetry Survey',\n",
       "  'abstract': 'The Refuge Cove bathymetry survey was acquired by Deakin University Marine Mapping lab onboard the M/V Yolla over 2 days in 2013 (07/06, 11/06) using a Kongsberg EM2040c. This survey was part of a Parks Victoria project to better understand the habitats and associated biodiversity of Wilsons Promontory MNP.',\n",
       "  'lineage': 'The Refuge Cove bathymetry survey was acquired by Deakin University Marine Mapping lab onboard the M/V Yolla over 2 days in 2013 (07/06, 11/06) using a Kongsberg EM2040c. This survey was part of a Parks Victoria project to better understand the habitats and associated biodiversity of Wilsons Promontory MNP. The data were originally processed in an earlier version of CARIS but have since been upgraded to  CARIS 11.3 and the following processing steps were\\nperformed.\\n1. Import into CARIS\\n2. Post-process POS MV data in POSPAC (PPP solution)\\n3. Apply SBETS to data in CARIS\\n4. Georeferenced bathymetry and computed TPU\\n5. Generated a CUBE surface  \\n6. Manually removed any erroneous soundings ',\n",
       "  'data_collected': ['Bathymetry', 'Backscatter'],\n",
       "  'keywords': ['AusSeabed', ' Marine', ' ']},\n",
       " 'survey_citation': {'data_owner': 'Deakin University',\n",
       "  'custodian': 'Geoscience Australia',\n",
       "  'point_of_contact/principal_investigator': 'Daniel Ierodiaconou',\n",
       "  'point_of_contact/principal_investigator_-_contact_details': 'iero@deakin.edu.au',\n",
       "  'collecting_entity': 'Deakin University',\n",
       "  'attribution_citation': 'Ierodiaconou, D. and Young, M.A. 2013. Deakin University Refuge Cove Multibeam Survey 2013.',\n",
       "  'legal_constraints_licence': 'Creative Commons — Attribution 4.0 International — CC BY 4.0',\n",
       "  'access_constraints': 'As per Licence',\n",
       "  'use_constraints': 'As per Licence',\n",
       "  'country_data_ownership': 'Australia'},\n",
       " 'survey_details': {'start_location': 'Warrnambool',\n",
       "  'end_location': 'Warrnambool',\n",
       "  'start_datetime': '2013-06-07T00:00:00',\n",
       "  'end_datetime': '2013-06-11T00:00:00',\n",
       "  'survey_area_general': 'Refuge Cove off Victoria',\n",
       "  'sea_areas': ['Southern Ocean', 'Southern Ocean'],\n",
       "  'bounding_box_coordinates': 'Min X: 425918.75\\nMax Y: 5680276.25\\nMax X: 460663.75\\nMin Y: 5661641.25',\n",
       "  'coordinate_reference_system_bounding_box': 'WGS 84 UTM Zone 55 S ',\n",
       "  'coordinate_reference_system_survey_data': 'WGS 84 UTM Zone 55 S ',\n",
       "  'horizontal_datum': 'WGS84',\n",
       "  'vertical_datum': 'Ellipsoid',\n",
       "  'coordinate_epoch': 'June 7 2013 - June 11 2013'},\n",
       " 'survey_technical': {'platform_class': 'Research Vessel',\n",
       "  'platform_name': 'M/V Yolla',\n",
       "  'geometries': 'Attach separately - Optional Highly recommended'},\n",
       " 'bathymetry_general': {'abstract': 'The Refuge Cove bathymetry survey was acquired by Deakin University Marine Mapping lab onboard the M/V Yolla over 2 days in 2013 (07/06, 11/06) using a Kongsberg EM2040c. This survey was part of a Parks Victoria project to better understand the habitats and associated biodiversity of Wilsons Promontory MNP.',\n",
       "  'lineage': 'The Refuge Cove bathymetry survey was acquired by Deakin University Marine Mapping lab onboard the M/V Yolla over 2 days in 2013 (07/06, 11/06) using a Kongsberg EM2040c. This survey was part of a Parks Victoria project to better understand the habitats and associated biodiversity of Wilsons Promontory MNP. The data were originally processed in an earlier version of CARIS but have since been upgraded to  CARIS 11.3 and the following processing steps were\\nperformed.\\n1. Import into CARIS\\n2. Post-process POS MV data in POSPAC (PPP solution)\\n3. Apply SBETS to data in CARIS\\n4. Georeferenced bathymetry and computed TPU\\n5. Generated a CUBE surface  \\n6. Manually removed any erroneous soundings ',\n",
       "  'data_collected': ['Bathymetry', 'Backscatter'],\n",
       "  'keywords': ['AusSeabed', ' Marine', ' ']},\n",
       " 'bathymetry_citation': {'data_owner': 'Deakin University',\n",
       "  'custodian': 'Geoscience Australia',\n",
       "  'point_of_contact/principal_investigator': 'Daniel Ierodiaconou',\n",
       "  'point_of_contact/principal_investigator_-_contact_details': 'iero@deakin.edu.au',\n",
       "  'collecting_entity': 'Deakin University',\n",
       "  'attribution_citation': 'Ierodiaconou, D. and Young, M.A. 2013. Deakin University Refuge Cove Multibeam Survey 2013.',\n",
       "  'legal_constraints_licence': 'Creative Commons — Attribution 4.0 International — CC BY 4.0',\n",
       "  'access_constraints': 'As per Licence',\n",
       "  'use_constraints': 'As per Licence',\n",
       "  'country_data_ownership': 'Australia'},\n",
       " 'bathymetry_details': {'start_location': 'Warrnambool',\n",
       "  'end_location': 'Warrnambool',\n",
       "  'start_datetime': '2013-06-07T00:00:00',\n",
       "  'end_datetime': '2013-06-11T00:00:00',\n",
       "  'survey_area_general': 'Refuge Cove off Victoria',\n",
       "  'sea_areas': 'Southern Ocean',\n",
       "  'bounding_box_coordinates': 'Min X: 452456.5\\nMax Y: 5679525.5\\nMax X: 454980.5\\nMin Y: 5678112.5',\n",
       "  'coordinate_reference_system_bounding_box': 'WGS 84 UTM Zone 55 S ',\n",
       "  'coordinate_reference_system_bathy_data': 'WGS 84 UTM Zone 55 S ',\n",
       "  'horizontal_datum': 'WGS84',\n",
       "  'vertical_datum': 'Ellipsoid',\n",
       "  'coordinate_epoch': 'June 7 2013 - June 11 2013'},\n",
       " 'bathymetry_technical': {'platform_speed': '1.5-3',\n",
       "  'platform__speed_units': 'm/s',\n",
       "  'instrument_type': 'Multi-beam echosounder',\n",
       "  'sensor_type': 'Kongsberg EM2040c',\n",
       "  'year_of_installation': 2013,\n",
       "  'sensor_parameter': 'Frequency',\n",
       "  'nominal_sensor_value': 300,\n",
       "  'sensor_uom': 'kHz',\n",
       "  'geometries': 'Attach separately - Optional but Highly recommended'}}"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asb_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "b02c75cd-029c-418b-b825-ed53ed661c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "crs_info = {\n",
    "    \"horizontal_datum\": \"epsg:4326\",\n",
    "    \"vertical_data\": \"epsg:4326\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "046009c8-c1af-442d-8ae7-7cb97f449998",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tiledb.open(array_uri, \"w\", ctx=ctx) as ds:\n",
    "    ds.meta[\"crs_info\"] = json.dumps(crs_info)\n",
    "    ds.meta[\"basic_statistics\"] = json.dumps(stats_results, cls=stac_metadata.Encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "902206b9-5aca-4caa-b804-2db67e9515e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_metadata = stac_metadata.prepare(\n",
    "    uid,\n",
    "    sonar_metadata,\n",
    "    stats_results,\n",
    "    asb_metadata,\n",
    "    array_uri,\n",
    "    coverage_uri,\n",
    "    soundings_cell_density_uri,\n",
    "    creds.access_key,\n",
    "    creds.secret_key,\n",
    "    final_start_end_timestamps,\n",
    "    outdir_uri,\n",
    "    stac_md_uri,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0115db8-ce7c-4d6c-a373-37d163affc2b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
